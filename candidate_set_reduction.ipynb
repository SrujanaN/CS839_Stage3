{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Stage 3: Entity Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the raw data from the source tables\n",
    "Read the raw data which was extracted from IMDb and Rotten Tomatoes\n",
    "Also read the Candidate Set extracted from Cloudmatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_A = 'IMDB_dataset'\n",
    "table_B = 'RottenTomato_data'\n",
    "\n",
    "dfa = pd.read_csv(table_A)\n",
    "dfb = pd.read_csv(table_B)\n",
    "dfc = pd.read_csv('Candidate_set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "In this step we will perform data cleaning to enhance entity matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove irrelevant columns altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfa['genre']\n",
    "del dfa['Up_System']\n",
    "del dfa['Release Date']\n",
    "del dfa['Rating']\n",
    "del dfa['Runtime']\n",
    "\n",
    "del dfb['genre']\n",
    "del dfb['Up_System']\n",
    "del dfb['Release Date']\n",
    "del dfb['Rating']\n",
    "del dfb['Runtime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert object datatype to String for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.ReleaseYear = dfa.ReleaseYear.astype(str)\n",
    "dfb.ReleaseYear = dfb.ReleaseYear.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate set to Full Entity conversion\n",
    "In this step we read the id references from candidate sets and corresponding entities from the source tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_ac = []\n",
    "table_bc = []\n",
    "for items in dfc.values.tolist():\n",
    "    table_ac.append(dfa[dfa['_id'] == items[0]].values.tolist()[0])\n",
    "    table_bc.append(dfb[dfb['_id'] == items[1]].values.tolist()[0])\n",
    "    \n",
    "# Convert list of tuples to dataframe and set column names and indexes\n",
    "table_ac = pd.DataFrame(table_ac, columns = ['_id','Name','ReleaseYear','Runtime','Director Name','Certificate']) \n",
    "table_bc = pd.DataFrame(table_bc, columns = ['_id','Name','ReleaseYear','Runtime','Director Name','Certificate']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocking Rule 1\n",
    "In this rule, we check if the release years of the entities has an absolute difference of less than equal to 1. If the difference is greater than 1, we BLOCK the match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_prime_dict = []\n",
    "\n",
    "for ind in range(table_ac.shape[0]):\n",
    "    a_item = table_ac.iloc[[ind]]\n",
    "    b_item = table_bc.iloc[[ind]]\n",
    "    a_rel_year_str = a_item['ReleaseYear'].item()\n",
    "    b_rel_year_str = b_item['ReleaseYear'].item()\n",
    "        \n",
    "    # Adding try catch here as the data column can have incorrect values\n",
    "    # like nan, NAN, HbO, Random, etc.\n",
    "    try:\n",
    "        a_rel_year_int = int(a_rel_year_str)\n",
    "    except ValueError:\n",
    "        a_rel_year_int = 0\n",
    "        \n",
    "    try:\n",
    "        b_rel_year_int = int(b_rel_year_str)\n",
    "    except ValueError:\n",
    "        b_rel_year_int = 0\n",
    "    \n",
    "    if abs(a_rel_year_int - b_rel_year_int) <= 1:\n",
    "        a = a_item['_id']\n",
    "        b = b_item['_id']\n",
    "        row_data = []\n",
    "        row_data.append(a.item())\n",
    "        row_data.append(b.item())\n",
    "        c_prime_dict.append(row_data)\n",
    "        \n",
    "c_prime = pd.DataFrame(c_prime_dict, columns = ['A_id','B_id']) \n",
    "c_prime.to_csv('candidate_set_after_first_block_rule_on_rel_year.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Jaccard measure function for second blocking rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_jaccard(string1,string2):\n",
    "    setA=[]\n",
    "    setB=[]\n",
    "    count=0\n",
    "    for i in range(0, len(string1) - 2):\n",
    "        setA.append(string1[i : i + 3])\n",
    "    for i in range(0, len(string2) - 2):\n",
    "        setB.append(string2[i : i + 3])\n",
    "    for item in setA:\n",
    "        if item in setB:\n",
    "            count = count + 1\n",
    "    return float(count) / (len(string1) + len(string2) - count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocking Rule 2\n",
    "We apply blocking rule 2 on the output of blocking rule 1. In this rule, we check the following\n",
    "1. Jaccard measure of the 3 grams on the Movie Name >= 0.6\n",
    "2. Jaccard measure of the 3 grams on the Movie Name is between (0.3, 0.6)\n",
    "- Release year should have an absolute difference of 1 year\n",
    "- Jaccard measure between Director Name > 0.6\n",
    "\n",
    "The second part of this rule is applied to retrieve the following kind of entity matches:\n",
    "1. MISSION: IMPOSSIBLE II v/s MISSION: IMPOSSIBLE 2\n",
    "2. LES QUATRE CENTS COUPS v/s THE 400 BLOWS (LES QUATRE CENTS COUPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_prime_dict_after_name_blocking = []\n",
    "\n",
    "for i in range(0,len(c_prime)):\n",
    "    a_loc = c_prime.iloc[i,0]\n",
    "    b_loc = c_prime.iloc[i,1]\n",
    "    stringA=str(dfa.iloc[a_loc,1]).upper()\n",
    "    stringB=str(dfb.iloc[b_loc,1]).upper()\n",
    "    jacc_score = check_jaccard('##' + stringA + '##','##' + stringB + '##')\n",
    "    \n",
    "    if jacc_score >= 0.6:\n",
    "        a_item = dfa.iloc[[a_loc]]\n",
    "        b_item = dfb.iloc[[b_loc]]\n",
    "        a = a_item['_id']\n",
    "        b = b_item['_id']\n",
    "        row_data = []\n",
    "        row_data.append(a.item())\n",
    "        row_data.append(b.item())\n",
    "        c_prime_dict_after_name_blocking.append(row_data)\n",
    "\n",
    "    elif jacc_score < 0.6 and jacc_score > 0.3:\n",
    "        a_item = dfa.iloc[[a_loc]]\n",
    "        b_item = dfb.iloc[[b_loc]]\n",
    "        a_rel_year_str = a_item['ReleaseYear'].item()\n",
    "        b_rel_year_str = b_item['ReleaseYear'].item()\n",
    "\n",
    "        try:\n",
    "            a_rel_year_int = int(a_rel_year_str)\n",
    "        except ValueError:\n",
    "            a_rel_year_int = 0\n",
    "\n",
    "        try:\n",
    "            b_rel_year_int = int(b_rel_year_str)\n",
    "        except ValueError:\n",
    "            b_rel_year_int = 0\n",
    "\n",
    "        if abs(a_rel_year_int - b_rel_year_int) <= 1:\n",
    "            \n",
    "            dir_A = a_item['Director Name'].item().upper()\n",
    "            dir_B = b_item['Director Name'].item().upper()\n",
    "            jacc_score_dir = check_jaccard('##' + dir_A + '##','##' + dir_B + '##')\n",
    "            if jacc_score_dir > 0.6:\n",
    "                \n",
    "                a = a_item['_id']\n",
    "                b = b_item['_id']\n",
    "                row_data = []\n",
    "                row_data.append(a.item())\n",
    "                row_data.append(b.item())\n",
    "                c_prime_dict_after_name_blocking.append(row_data)\n",
    "                \n",
    "df_c_prime_dict_after_name_blocking = pd.DataFrame(c_prime_dict_after_name_blocking, columns = ['A_id','B_id'])\n",
    "df_c_prime_dict_after_name_blocking.to_csv('candidate_set_after_second_block_rule.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_prime_dict_after_name_blocking.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform debug_blocker step\n",
    "Here we performed the debug_blocker step and checked that out of the 200 entries reported, only 2 were True Positives. Thus our blocking rules are not dropping lot of TP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Manual Labeling on 50 samples\n",
    "Here we pick 50 samples from our final candidate set and manually label them. We got 2 FP out of 50, thus the density is 48/50 = 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_50 = df_c_prime_dict_after_name_blocking.sample(n=50, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Manual Labeling on 400 samples\n",
    "Here we pick 400 samples from our final candidate set and manually label them. We got 5 FP out of 400, thus the density is 395/400 = 0.9875\n",
    "\n",
    "By passing the same seed value, our first 50 samples remained the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_400 = df_c_prime_dict_after_name_blocking.sample(n=400, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving final Candidate Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_400.to_csv('final_candidate_set.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
